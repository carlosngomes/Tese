{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "features = \"features_new2.csv\"\n",
    "features = pd.read_csv(features, sep=',', header=0, index_col=None)\n",
    "Y = features[['Output']]\n",
    "# feat_not_theta = [i for i in features.columns if \"Theta\" not in i]\n",
    "# X = features.drop(feat_not_theta, axis=1)\n",
    "# not_time_feat = [i for i in features.columns if (\"ERN\" not in i) & (\"Pe\" not in i) & (\"amp\" not in i)]\n",
    "# X = features.drop(not_time_feat, axis=1)\n",
    "\n",
    "#not_freq_feat = [i for i in features.columns if (\"Delta\" not in i) & (\"Theta\" not in i) & (\"Alpha\" not in i) &\n",
    " #                (\"Freq\" not in i)]\n",
    "#X = features.drop(not_freq_feat, axis=1)\n",
    "# X = features.drop('Participant', axis=1)\n",
    "X = features.drop('Output', axis=1)\n",
    "print(len(X.columns)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n",
    "selected_features = mrmr_classif(X=X, y=Y, K=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=pd.DataFrame()\n",
    "for i in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X[i]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with coefficient of variation < 0.2\n",
    "variance = X.std()/X.mean()\n",
    "low_variance = [i for i in variance.index if variance[i] < 0.2]\n",
    "X = X.drop(low_variance, axis=1)\n",
    "print(len(X.columns))\n",
    "\n",
    "y0 = Y[Y['Output'] == 0]\n",
    "feat_corr = np.zeros(len(X.columns))\n",
    "feat_ttest = np.zeros(len(X.columns))\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "\n",
    "i = 0\n",
    "splits = 100\n",
    "sss = StratifiedShuffleSplit(n_splits=splits, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    ind_y0 = [j for j in range(0, len(X_train)) if X_train.index[j] in y0.index]\n",
    "    ind_y1 = [j for j in range(0, len(X_train)) if X_train.index[j] not in y0.index]\n",
    "    X_ind_y0 = X_train.iloc[ind_y0, :]\n",
    "    X_ind_y1 = X_train.iloc[ind_y1, :]\n",
    "\n",
    "    corr = []\n",
    "\n",
    "    # Remove correlated features\n",
    "    for col1 in range(0, len(X.columns)-1):\n",
    "        for col2 in range(col1+1, len(X.columns)):\n",
    "            if abs(np.corrcoef(X_train[X.columns[col1]], X_train[X.columns[col2]])[0, 1]) > 0.9:\n",
    "                if stats.ttest_ind(X_ind_y0[X.columns[col1]], X_ind_y1[X.columns[col1]]).pvalue < \\\n",
    "                        stats.ttest_ind(X_ind_y0[X.columns[col2]], X_ind_y1[X.columns[col2]]).pvalue:\n",
    "                    if col2 not in corr:\n",
    "                        feat_corr[col2] += 1\n",
    "                        corr.append(col2)\n",
    "                    elif col1 not in corr:\n",
    "                        feat_corr[col1] += 1\n",
    "                        corr.append(col1)\n",
    "\n",
    "    # Relevance: t-test between independent variables and output\n",
    "    ttest = [stats.ttest_ind(X_ind_y0[col], X_ind_y1[col])[1] for col in X.columns]\n",
    "    ttest_order = np.argsort(ttest)\n",
    "    feat_ttest += np.argsort(ttest_order)  # min(p-value) -> +0, max(p-value) -> +len(X.columns)-1\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(len(list(X.columns[feat_corr > splits/2])))\n",
    "X = X.drop(list(X.columns[feat_corr > splits/2]), axis=1)  # Remove correlated features\n",
    "feat_ttest = feat_ttest[feat_corr <= splits/2]\n",
    "\n",
    "X = X.drop(X.columns[np.argsort(np.argsort(feat_ttest)) >= 40], axis=1)\n",
    "feat_ttest = feat_ttest[np.argsort(np.argsort(feat_ttest)) < 40]\n",
    "Xcol_sort = [x for _, x in sorted(zip(feat_ttest, X.columns))]\n",
    "print(Xcol_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6341176470588237\n",
      "0.0549567303843021\n",
      "0.8830283911671925\n",
      "0.022085083158282438\n",
      "0.7585730191130078\n",
      "0.025534166112890288\n"
     ]
    }
   ],
   "source": [
    "#  ================================================== Classification ===================================================\n",
    "\n",
    "f1score = []\n",
    "precision = []\n",
    "recall = []\n",
    "specificity = []\n",
    "npv = []\n",
    "bal_acc = []\n",
    "\n",
    "splits = 100\n",
    "sss = StratifiedShuffleSplit(n_splits=splits, test_size=0.3, random_state=0)\n",
    "svm = SVC(class_weight='balanced')\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_col = combined_df.columns\n",
    "Y=np.array(Y)\n",
    "\n",
    "for train_index, test_index in sss.split(combined_df, Y):\n",
    "    X_train, X_test = combined_df.iloc[train_index, :], combined_df.iloc[test_index, :]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    scal = scaler.fit(X_train)\n",
    "    X_train = scal.transform(X_train)  # Variables standardization\n",
    "    X_test = scal.transform(X_test)  # Variables standardization\n",
    "    X_train = pd.DataFrame(X_train, columns=X_col)\n",
    "    X_test = pd.DataFrame(X_test, columns=X_col)\n",
    "    clf = svm.fit(X_train, Y_train)\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    f1score.append(f1_score(Y_test, Y_predicted))\n",
    "    precision.append(precision_score(Y_test, Y_predicted))  # Precision = Positive predictive value\n",
    "    npv.append(precision_score(Y_test, Y_predicted, pos_label=0))  # Negative predictive value\n",
    "    recall.append(recall_score(Y_test, Y_predicted))  # Recall = Sensitivity\n",
    "    specificity.append(recall_score(Y_test, Y_predicted, pos_label=0))\n",
    "    bal_acc.append(balanced_accuracy_score(Y_test, Y_predicted))\n",
    "\n",
    "# print(np.mean(f1score))\n",
    "# print(np.mean(precision))\n",
    "print(np.mean(recall))\n",
    "print(np.std(recall))\n",
    "print(np.mean(specificity))\n",
    "print(np.std(specificity))\n",
    "# print(np.mean(npv))\n",
    "print(np.mean(bal_acc))\n",
    "print(np.std(bal_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
