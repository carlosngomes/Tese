{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features:\n",
      "Total: 1629\n",
      "Pre: 844\n",
      "Post: 846\n",
      "Theta Features:\n",
      "Total: 667\n",
      "Pre: 364\n",
      "Post: 364\n",
      "Frequency Features:\n",
      "Total: 1387\n",
      "Pre: 724\n",
      "Post: 724\n",
      "Temporal Features:\n",
      "Total: 242\n",
      "Pre: 120\n",
      "Post: 122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import src.functions as src\n",
    "\n",
    "features = \"dataset1_features.csv\"\n",
    "features = pd.read_csv(features, sep=',', header=0, index_col=None)\n",
    "Y = features[['labels']]\n",
    "\n",
    "X_all = features.drop('labels', axis=1)\n",
    "all_pre= ['3_','4_','6_','7_','10_','11_','12_','15_','16_','18_','25_','26_','27_','28_','29_','30_','33_','34_']\n",
    "X_all_pre=X_all[[col for col in X_all.columns if any(col.startswith(prefix) for prefix in all_pre)]]\n",
    "all_post=  ['1_','2_','5_','7_','8_','9_','12_','13_','14_','17_','19_','20_','21_','22_','23_','24_','31_','32_','35_','36_']\n",
    "X_all_post=X_all[[col for col in X_all.columns if any(col.startswith(prefix) for prefix in all_post)]]\n",
    "print('All Features:')\n",
    "print('Total: ' + str(len(X_all.columns))) \n",
    "print('Pre: ' + str(len(X_all_pre.columns)))\n",
    "print('Post: ' + str(len(X_all_post.columns)))\n",
    "\n",
    "theta_prefixes= ['1_','2_','3_','4_','5_','6_','7_','8_','9_','10_','11_','12_','13_','14_','15_','16_','17_','18_']\n",
    "X_theta= X_all[[col for col in X_all.columns if any(col.startswith(prefix) for prefix in theta_prefixes)]]\n",
    "theta_pre= ['3_','4_','6_','7_','10_','11_','12_','15_','16_','18_']\n",
    "X_theta_pre= X_theta[[col for col in X_theta.columns if any(col.startswith(prefix) for prefix in theta_pre)]]\n",
    "theta_post= ['1_','2_','5_','7_','8_','9_','12_','13_','14_','17_']\n",
    "X_theta_post= X_theta[[col for col in X_theta.columns if any(col.startswith(prefix) for prefix in theta_post)]]\n",
    "print('Theta Features:')\n",
    "print('Total: ' + str(len(X_theta.columns)))\n",
    "print('Pre: ' + str(len(X_theta_pre.columns)))\n",
    "print('Post: ' + str(len(X_theta_post.columns)))\n",
    "\n",
    "frequency_prefixes= ['1_','2_','3_','4_','5_','6_','7_','8_','9_','10_','11_','12_','13_','14_','15_','16_','17_','18_','19_','20_','21_','22_','23_','24_','25_','26_','27_','28_','29_','30_']\n",
    "X_frequency= X_all[[col for col in X_all.columns if any(col.startswith(prefix) for prefix in frequency_prefixes)]]\n",
    "frequency_pre=['3_','4_','6_','7_','10_','11_','12_','15_','16_','18_','25_','26_','27_','28_','29_','30_']\n",
    "X_frequency_pre= X_frequency[[col for col in X_frequency.columns if any(col.startswith(prefix) for prefix in frequency_pre)]]\n",
    "frequency_post=['1_','2_','5_','7_','8_','9_','12_','13_','14_','17_','19_','20_','21_','22_','23_','24_']\n",
    "X_frequency_post= X_frequency[[col for col in X_frequency.columns if any(col.startswith(prefix) for prefix in frequency_post)]]\n",
    "print('Frequency Features:')\n",
    "print('Total: ' + str(len(X_frequency.columns)))\n",
    "print('Pre: ' + str(len(X_frequency_pre.columns)))\n",
    "print('Post: ' + str(len(X_frequency_post.columns)))\n",
    "\n",
    "temporal_prefixes= ['31_','32_','33_','34_','35_','36_']\n",
    "X_temporal= X_all[[col for col in X_all.columns if any(col.startswith(prefix) for prefix in temporal_prefixes)]]\n",
    "temporal_pre= ['33_','34_']\n",
    "X_temporal_pre= X_temporal[[col for col in X_temporal.columns if any(col.startswith(prefix) for prefix in temporal_pre)]] \n",
    "temporal_post= ['31_','32_','35_','36_']\n",
    "X_temporal_post= X_temporal[[col for col in X_temporal.columns if any(col.startswith(prefix) for prefix in temporal_post)]]\n",
    "print('Temporal Features:')\n",
    "print('Total: ' + str(len(X_temporal.columns)))\n",
    "print('Pre: ' + str(len(X_temporal_pre.columns)))\n",
    "print('Post: ' + str(len(X_temporal_post.columns)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theta Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrmr import mrmr_classif\n",
    "\n",
    "selected_features = mrmr_classif(X=X_theta, y=Y, K=30)\n",
    "combined_df=pd.DataFrame()\n",
    "for i in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X_theta[i]], axis=1)\n",
    "Theta_features=combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrmr import mrmr_classif\n",
    "\n",
    "selected_features = mrmr_classif(X=X_frequency, y=Y, K=30)\n",
    "combined_df=pd.DataFrame()\n",
    "for i in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X_frequency[i]], axis=1)\n",
    "Frequency_features=combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrmr import mrmr_classif\n",
    "\n",
    "selected_features = mrmr_classif(X=X_temporal, y=Y, K=30)\n",
    "combined_df=pd.DataFrame()\n",
    "for i in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X_temporal[i]], axis=1)\n",
    "Temporal_features=combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used: 30\n",
      "Test Size: 0.50\n",
      "Mean Sensitivity: 0.3269\n",
      "Std Sensitivity: 0.0484\n",
      "Mean Specificity: 0.9206\n",
      "Std Specificity: 0.0125\n",
      "Mean Balanced Accuracy: 0.6237\n",
      "Std Balanced Accuracy: 0.0221\n",
      "Number of features used: 30\n",
      "Test Size: 0.45\n",
      "Mean Sensitivity: 0.3243\n",
      "Std Sensitivity: 0.0435\n",
      "Mean Specificity: 0.9215\n",
      "Std Specificity: 0.0136\n",
      "Mean Balanced Accuracy: 0.6229\n",
      "Std Balanced Accuracy: 0.0199\n",
      "Number of features used: 30\n",
      "Test Size: 0.40\n",
      "Mean Sensitivity: 0.3413\n",
      "Std Sensitivity: 0.0546\n",
      "Mean Specificity: 0.9168\n",
      "Std Specificity: 0.0128\n",
      "Mean Balanced Accuracy: 0.6290\n",
      "Std Balanced Accuracy: 0.0254\n",
      "Number of features used: 30\n",
      "Test Size: 0.35\n",
      "Mean Sensitivity: 0.3439\n",
      "Std Sensitivity: 0.0530\n",
      "Mean Specificity: 0.9178\n",
      "Std Specificity: 0.0123\n",
      "Mean Balanced Accuracy: 0.6308\n",
      "Std Balanced Accuracy: 0.0247\n",
      "Number of features used: 30\n",
      "Test Size: 0.30\n",
      "Mean Sensitivity: 0.3424\n",
      "Std Sensitivity: 0.0667\n",
      "Mean Specificity: 0.9133\n",
      "Std Specificity: 0.0119\n",
      "Mean Balanced Accuracy: 0.6278\n",
      "Std Balanced Accuracy: 0.0317\n",
      "Number of features used: 30\n",
      "Test Size: 0.25\n",
      "Mean Sensitivity: 0.3576\n",
      "Std Sensitivity: 0.0725\n",
      "Mean Specificity: 0.9128\n",
      "Std Specificity: 0.0138\n",
      "Mean Balanced Accuracy: 0.6352\n",
      "Std Balanced Accuracy: 0.0340\n",
      "Number of features used: 30\n",
      "Test Size: 0.20\n",
      "Mean Sensitivity: 0.3541\n",
      "Std Sensitivity: 0.0843\n",
      "Mean Specificity: 0.9125\n",
      "Std Specificity: 0.0135\n",
      "Mean Balanced Accuracy: 0.6333\n",
      "Std Balanced Accuracy: 0.0411\n",
      "Number of features used: 30\n",
      "Test Size: 0.15\n",
      "Mean Sensitivity: 0.3556\n",
      "Std Sensitivity: 0.0938\n",
      "Mean Specificity: 0.9096\n",
      "Std Specificity: 0.0144\n",
      "Mean Balanced Accuracy: 0.6326\n",
      "Std Balanced Accuracy: 0.0457\n",
      "Number of features used: 30\n",
      "Test Size: 0.10\n",
      "Mean Sensitivity: 0.3653\n",
      "Std Sensitivity: 0.1180\n",
      "Mean Specificity: 0.9097\n",
      "Std Specificity: 0.0179\n",
      "Mean Balanced Accuracy: 0.6375\n",
      "Std Balanced Accuracy: 0.0580\n",
      "Number of features used: 30\n",
      "Test Size: 0.05\n",
      "Mean Sensitivity: 0.3700\n",
      "Std Sensitivity: 0.1767\n",
      "Mean Specificity: 0.9094\n",
      "Std Specificity: 0.0221\n",
      "Mean Balanced Accuracy: 0.6397\n",
      "Std Balanced Accuracy: 0.0873\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The test_size = 1 should be greater or equal to the number of classes = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m X_col \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     34\u001b[0m Y\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(Y)\n\u001b[1;32m---> 36\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:1749\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m \n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1749\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2163\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2161\u001b[0m     )\n\u001b[0;32m   2162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_test \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[1;32m-> 2163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2164\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe test_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_test, n_classes)\n\u001b[0;32m   2166\u001b[0m     )\n\u001b[0;32m   2168\u001b[0m \u001b[38;5;66;03m# Find the sorted list of instances for each class:\u001b[39;00m\n\u001b[0;32m   2169\u001b[0m \u001b[38;5;66;03m# (np.unique above performs a sort, so code is O(n logn) already)\u001b[39;00m\n\u001b[0;32m   2170\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(\n\u001b[0;32m   2171\u001b[0m     np\u001b[38;5;241m.\u001b[39margsort(y_indices, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmergesort\u001b[39m\u001b[38;5;124m\"\u001b[39m), np\u001b[38;5;241m.\u001b[39mcumsum(class_counts)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   2172\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: The test_size = 1 should be greater or equal to the number of classes = 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.signal as signal\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, balanced_accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from mrmr import mrmr_classif\n",
    "\n",
    "selected_features = mrmr_classif(X=X_all, y=Y, K=30)\n",
    "combined_df=pd.DataFrame()\n",
    "for i in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X_all[i]], axis=1)\n",
    "All_features=combined_df\n",
    "\n",
    "X=All_features\n",
    "i=30\n",
    "test=0.5\n",
    "while test>=0.1:\n",
    "    f1score = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    specificity = []\n",
    "    npv = []\n",
    "    bal_acc = []\n",
    "\n",
    "    splits = 100\n",
    "    sss = StratifiedShuffleSplit(n_splits=splits, test_size=test, random_state=0)\n",
    "    svm = SVC(class_weight='balanced')\n",
    "    scaler = StandardScaler()\n",
    "    X_col = X.columns\n",
    "    Y=np.array(Y)\n",
    "\n",
    "    for train_index, test_index in sss.split(X, Y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        scal = scaler.fit(X_train)\n",
    "        X_train = scal.transform(X_train)  # Variables standardization\n",
    "        X_test = scal.transform(X_test)  # Variables standardization\n",
    "        X_train = pd.DataFrame(X_train, columns=X_col)\n",
    "        X_test = pd.DataFrame(X_test, columns=X_col)\n",
    "        clf = svm.fit(X_train, Y_train)\n",
    "        Y_predicted = clf.predict(X_test)\n",
    "        f1score.append(f1_score(Y_test, Y_predicted))\n",
    "        precision.append(precision_score(Y_test, Y_predicted))  # Precision = Positive predictive value\n",
    "        npv.append(precision_score(Y_test, Y_predicted, pos_label=0))  # Negative predictive value\n",
    "        recall.append(recall_score(Y_test, Y_predicted))  # Recall = Sensitivity\n",
    "        specificity.append(recall_score(Y_test, Y_predicted, pos_label=0))\n",
    "        bal_acc.append(balanced_accuracy_score(Y_test, Y_predicted))\n",
    "\n",
    "    print(\"Number of features used: \"+ str(i))\n",
    "    print(\"Test Size: {:.2f}\".format(test))\n",
    "    print(\"Mean Sensitivity: {:.4f}\".format(np.mean(recall)))\n",
    "    print(\"Std Sensitivity: {:.4f}\".format(np.std(recall)))\n",
    "    print(\"Mean Specificity: {:.4f}\".format(np.mean(specificity)))\n",
    "    print(\"Std Specificity: {:.4f}\".format(np.std(specificity)))\n",
    "    print(\"Mean Balanced Accuracy: {:.4f}\".format(np.mean(bal_acc)))\n",
    "    print(\"Std Balanced Accuracy: {:.4f}\".format(np.std(bal_acc)))\n",
    "    test=test-0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.functions' from 'c:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\Tese\\\\src\\\\functions.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.signal as signal\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, balanced_accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from mrmr import mrmr_classif\n",
    "\n",
    "selected_features = mrmr_classif(X=X_all, y=Y, K=30)\n",
    "combined_df=pd.DataFrame()\n",
    "for feature in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X_all[feature]], axis=1)\n",
    "X=combined_df\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "grid = GridSearchCV(SVC(class_weight='balanced'), param_grid, refit=True, verbose=2, n_jobs=-1)\n",
    "grid.fit(X, Y)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f\"Best parameters found: {grid.best_params_}\")\n",
    "\n",
    "# Now use the best parameters for Stratified Shuffle Split\n",
    "best_params = grid.best_params_\n",
    "svm = SVC(class_weight='balanced', **best_params)\n",
    "\n",
    "f1score = []\n",
    "precision = []\n",
    "recall = []\n",
    "specificity = []\n",
    "npv = []\n",
    "bal_acc = []\n",
    "\n",
    "splits = 100\n",
    "sss = StratifiedShuffleSplit(n_splits=splits, test_size=0.3, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "X_col = X.columns\n",
    "Y = np.array(Y)\n",
    "\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    scal = scaler.fit(X_train)\n",
    "    X_train = scal.transform(X_train)  # Variables standardization\n",
    "    X_test = scal.transform(X_test)  # Variables standardization\n",
    "    X_train = pd.DataFrame(X_train, columns=X_col)\n",
    "    X_test = pd.DataFrame(X_test, columns=X_col)\n",
    "    clf = svm.fit(X_train, Y_train)\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    f1score.append(f1_score(Y_test, Y_predicted))\n",
    "    precision.append(precision_score(Y_test, Y_predicted))  # Precision = Positive predictive value\n",
    "    npv.append(precision_score(Y_test, Y_predicted, pos_label=0))  # Negative predictive value\n",
    "    recall.append(recall_score(Y_test, Y_predicted))  # Recall = Sensitivity\n",
    "    specificity.append(recall_score(Y_test, Y_predicted, pos_label=0))\n",
    "    bal_acc.append(balanced_accuracy_score(Y_test, Y_predicted))\n",
    "\n",
    "print(\"Number of features used: \"+ str(X.shape[1]))\n",
    "print(\"Mean Sensitivity: {:.4f}\".format(np.mean(recall)))\n",
    "print(\"Std Sensitivity: {:.4f}\".format(np.std(recall)))\n",
    "print(\"Mean Specificity: {:.4f}\".format(np.mean(specificity)))\n",
    "print(\"Std Specificity: {:.4f}\".format(np.std(specificity)))\n",
    "print(\"Mean Balanced Accuracy: {:.4f}\".format(np.mean(bal_acc)))\n",
    "print(\"Std Balanced Accuracy: {:.4f}\".format(np.std(bal_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n",
    "i=10\n",
    "while i <= 50:\n",
    "    selected_features = mrmr_classif(X=X_all, y=Y, K=i)\n",
    "    combined_df=pd.DataFrame()\n",
    "    for feature in selected_features:\n",
    "        combined_df=pd.concat([combined_df, X_all[feature]], axis=1)\n",
    "    X=combined_df\n",
    "    src.classification(i,X,Y)\n",
    "    i=i+5\n",
    "print(\"Done\") #melhor antes foi 66.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
