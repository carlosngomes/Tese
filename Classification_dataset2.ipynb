{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1629\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import src.functions as src\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "features = \"dataset2_features.csv\"\n",
    "features = pd.read_csv(features, sep=',', header=0, index_col=None)\n",
    "Y = features[['labels']]\n",
    "# feat_not_theta = [i for i in features.columns if \"Theta\" not in i]\n",
    "# X = features.drop(feat_not_theta, axis=1)\n",
    "# not_time_feat = [i for i in features.columns if (\"ERN\" not in i) & (\"Pe\" not in i) & (\"amp\" not in i)]\n",
    "# X = features.drop(not_time_feat, axis=1)\n",
    "\n",
    "#not_freq_feat = [i for i in features.columns if (\"Delta\" not in i) & (\"Theta\" not in i) & (\"Alpha\" not in i) &\n",
    " #                (\"Freq\" not in i)]\n",
    "#X = features.drop(not_freq_feat, axis=1)\n",
    "# X = features.drop('Participant', axis=1)\n",
    "X = features.drop('labels', axis=1)\n",
    "print(len(X.columns)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "29\n",
      "['1_0', '7_0', '8_F1', '12_F1', '8_F3', '8_FZ', '12_FZ', '12_AF3', '8_FC1', '8_F2', '8_AF3', '12_F3', '21_F1', '17_FT7', '33_CZ', '21_FC1', '8_FC2', '21_FCZ', '21_F3', '8_F4', '21_FZ', '21_CZ', '12_FC1', '12_F4', '12_F2', '35_CZ', '8_FC3', '8_POZ', '35_CPZ', '35_C1', '17_F1', '20_PO4', '8_TP8', '18_FT7', '8_AF4', '21_F2', '12_FC3', '8_OZ', '10_P4', '27_P4']\n"
     ]
    }
   ],
   "source": [
    "# Remove features with coefficient of variation < 0.2\n",
    "variance = X.std()/X.mean()\n",
    "low_variance = [i for i in variance.index if variance[i] < 0.2]\n",
    "X1 = X.drop(low_variance, axis=1)\n",
    "print(len(X1.columns))\n",
    "\n",
    "y0 = Y[Y['labels'] == 0]\n",
    "feat_corr = np.zeros(len(X1.columns))\n",
    "feat_ttest = np.zeros(len(X1.columns))\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "i = 0\n",
    "splits = 100\n",
    "sss = StratifiedShuffleSplit(n_splits=splits, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X1, Y):\n",
    "    X_train, X_test = X1.iloc[train_index, :], X1.iloc[test_index, :]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    ind_y0 = [j for j in range(0, len(X_train)) if X_train.index[j] in y0.index]\n",
    "    ind_y1 = [j for j in range(0, len(X_train)) if X_train.index[j] not in y0.index]\n",
    "    X_ind_y0 = X_train.iloc[ind_y0, :]\n",
    "    X_ind_y1 = X_train.iloc[ind_y1, :]\n",
    "\n",
    "    corr = []\n",
    "\n",
    "    # Remove correlated features\n",
    "    for col1 in range(0, len(X1.columns)-1):\n",
    "        for col2 in range(col1+1, len(X1.columns)):\n",
    "            if abs(np.corrcoef(X_train[X1.columns[col1]], X_train[X1.columns[col2]])[0, 1]) > 0.9:\n",
    "                if stats.ttest_ind(X_ind_y0[X1.columns[col1]], X_ind_y1[X1.columns[col1]]).pvalue < \\\n",
    "                        stats.ttest_ind(X_ind_y0[X1.columns[col2]], X_ind_y1[X1.columns[col2]]).pvalue:\n",
    "                    if col2 not in corr:\n",
    "                        feat_corr[col2] += 1\n",
    "                        corr.append(col2)\n",
    "                    elif col1 not in corr:\n",
    "                        feat_corr[col1] += 1\n",
    "                        corr.append(col1)\n",
    "\n",
    "    # Relevance: t-test between independent variables and output\n",
    "    ttest = [stats.ttest_ind(X_ind_y0[col], X_ind_y1[col])[1] for col in X1.columns]\n",
    "    ttest_order = np.argsort(ttest)\n",
    "    feat_ttest += np.argsort(ttest_order)  # min(p-value) -> +0, max(p-value) -> +len(X.columns)-1\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(len(list(X1.columns[feat_corr > splits/2])))\n",
    "X1 = X1.drop(list(X1.columns[feat_corr > splits/2]), axis=1)  # Remove correlated features\n",
    "feat_ttest = feat_ttest[feat_corr <= splits/2]\n",
    "\n",
    "X1 = X1.drop(X1.columns[np.argsort(np.argsort(feat_ttest)) >= 40], axis=1)\n",
    "feat_ttest = feat_ttest[np.argsort(np.argsort(feat_ttest)) < 40]\n",
    "Xcol_sort = [x for _, x in sorted(zip(feat_ttest, X1.columns))]\n",
    "print(Xcol_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5740753424657534\n",
      "0.027829025046090826\n",
      "0.7290807017543861\n",
      "0.014642915377759783\n",
      "0.6515780221100697\n",
      "0.013140676809983404\n"
     ]
    }
   ],
   "source": [
    "f1score = []\n",
    "precision = []\n",
    "recall = []\n",
    "specificity = []\n",
    "npv = []\n",
    "bal_acc = []\n",
    "\n",
    "splits = 100\n",
    "sss = StratifiedShuffleSplit(n_splits=splits, test_size=0.3, random_state=0)\n",
    "svm = SVC(class_weight='balanced')\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_col = X.columns\n",
    "Y=np.array(Y)\n",
    "\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    scal = scaler.fit(X_train)\n",
    "    X_train = scal.transform(X_train)  # Variables standardization\n",
    "    X_test = scal.transform(X_test)  # Variables standardization\n",
    "    X_train = pd.DataFrame(X_train, columns=X_col)\n",
    "    X_test = pd.DataFrame(X_test, columns=X_col)\n",
    "    clf = svm.fit(X_train, Y_train)\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    f1score.append(f1_score(Y_test, Y_predicted))\n",
    "    precision.append(precision_score(Y_test, Y_predicted))  # Precision = Positive predictive value\n",
    "    npv.append(precision_score(Y_test, Y_predicted, pos_label=0))  # Negative predictive value\n",
    "    recall.append(recall_score(Y_test, Y_predicted))  # Recall = Sensitivity\n",
    "    specificity.append(recall_score(Y_test, Y_predicted, pos_label=0))\n",
    "    bal_acc.append(balanced_accuracy_score(Y_test, Y_predicted))\n",
    "\n",
    "# print(np.mean(f1score))\n",
    "# print(np.mean(precision))\n",
    "print(np.mean(recall))\n",
    "print(np.std(recall))\n",
    "print(np.mean(specificity))\n",
    "print(np.std(specificity))\n",
    "# print(np.mean(npv))\n",
    "print(np.mean(bal_acc))\n",
    "print(np.std(bal_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n",
    "selected_features = mrmr_classif(X=X, y=Y, K=30)\n",
    "combined_df=pd.DataFrame()\n",
    "for i in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X[i]], axis=1)\n",
    "X=combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=pd.DataFrame()\n",
    "for i in selected_features:\n",
    "    combined_df=pd.concat([combined_df, X[i]], axis=1)\n",
    "X=combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Sensitivity: 0.5965\n",
      "Std Sensitivity: 0.0255\n",
      "Mean Specificity: 0.7732\n",
      "Std Specificity: 0.0122\n",
      "Mean Balanced Accuracy: 0.6848\n",
      "Std Balanced Accuracy: 0.0123\n"
     ]
    }
   ],
   "source": [
    "src.classification(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6933417447728911,\n",
       " 0.6730749819754867,\n",
       " 0.6853977409276617,\n",
       " 0.7070127373227589,\n",
       " 0.6908014900264359,\n",
       " 0.6512496995914444,\n",
       " 0.6919802931987503,\n",
       " 0.6797837058399423,\n",
       " 0.707223023311704,\n",
       " 0.7045001201634222,\n",
       " 0.6688920932468156,\n",
       " 0.6923876472001923,\n",
       " 0.7086265320836338,\n",
       " 0.7024789714011055,\n",
       " 0.6942261475606826,\n",
       " 0.6948437875510695,\n",
       " 0.6752223023311704,\n",
       " 0.690549146839702,\n",
       " 0.689931506849315,\n",
       " 0.6870824321076665,\n",
       " 0.6794748858447488,\n",
       " 0.6565693342946407,\n",
       " 0.6806536890170631,\n",
       " 0.69014179283826,\n",
       " 0.6540422975246336,\n",
       " 0.6932011535688536,\n",
       " 0.686240086517664,\n",
       " 0.6760081711127133,\n",
       " 0.6919382360009613,\n",
       " 0.6893559240567171,\n",
       " 0.6829836577745734,\n",
       " 0.6752643595289594,\n",
       " 0.6801345830329248,\n",
       " 0.6892573900504686,\n",
       " 0.7050192261475607,\n",
       " 0.6891732756548907,\n",
       " 0.6766258111031003,\n",
       " 0.6772855082912761,\n",
       " 0.6834751261715933,\n",
       " 0.6809769286229272,\n",
       " 0.6781134342706081,\n",
       " 0.6784643114635904,\n",
       " 0.6675306416726748,\n",
       " 0.6853556837298727,\n",
       " 0.7003737082432108,\n",
       " 0.6917700072098054,\n",
       " 0.6921353040134584,\n",
       " 0.6940014419610671,\n",
       " 0.6587587118481135,\n",
       " 0.6768360970920452,\n",
       " 0.6642321557317953,\n",
       " 0.6781554914683969,\n",
       " 0.6818889689978371,\n",
       " 0.6838260033645758,\n",
       " 0.6699867820235521,\n",
       " 0.6772434510934872,\n",
       " 0.6870259552992068,\n",
       " 0.6989701994712809,\n",
       " 0.6598113434270608,\n",
       " 0.7041913001682287,\n",
       " 0.6872927180966113,\n",
       " 0.6973984619081952,\n",
       " 0.6868853640951694,\n",
       " 0.6708291276135544,\n",
       " 0.6868577265080509,\n",
       " 0.6709973564047105,\n",
       " 0.6705623648161501,\n",
       " 0.69901225666907,\n",
       " 0.6948858447488584,\n",
       " 0.6977769766882961,\n",
       " 0.6790819514539774,\n",
       " 0.6753905311223263,\n",
       " 0.6908435472242249,\n",
       " 0.6935808699831771,\n",
       " 0.670112953616919,\n",
       " 0.6778046142754146,\n",
       " 0.6911523672194184,\n",
       " 0.6754746455179044,\n",
       " 0.6845974525354482,\n",
       " 0.6776784426820476,\n",
       " 0.6900156212448931,\n",
       " 0.6663518385003605,\n",
       " 0.6945349675558761,\n",
       " 0.6907450132179764,\n",
       " 0.6889906272530641,\n",
       " 0.7143246815669311,\n",
       " 0.67753785147801,\n",
       " 0.6975246335015621,\n",
       " 0.6801766402307138,\n",
       " 0.6766678683008892,\n",
       " 0.6746467195385725,\n",
       " 0.6836157173756309,\n",
       " 0.6922470559961548,\n",
       " 0.6818889689978371,\n",
       " 0.6918961788031723,\n",
       " 0.6875174236962269,\n",
       " 0.7003737082432108,\n",
       " 0.6828995433789955,\n",
       " 0.6737767363614515,\n",
       " 0.7038824801730352]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_acc #teste de proporções, testar quao acima do chance level está\n",
    "#ROC curve\n",
    "#R^2\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5771232876712328\n",
    "0.026507291773589414\n",
    "0.7865192982456141\n",
    "0.012696245776507414\n",
    "0.6818212929584234\n",
    "0.01276152874444839"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
