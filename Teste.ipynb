{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import src.functions as src\n",
    "\n",
    "fs=500\n",
    "freq_bands={'delta' : [0,4],\n",
    "            'theta' : [4,8],\n",
    "            'alpha' : [8, 13],\n",
    "            'beta' : [13,35],\n",
    "            'high' : [35, 45],\n",
    "            'all': [1.5,45],\n",
    "            'low': [1.5,12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {}\n",
    "labels1 = {}\n",
    "file1= [item for item in os.listdir('data') if item.endswith('set')]\n",
    "\n",
    "for file_index, file_name in enumerate(file1):\n",
    "    path_ = os.path.join( 'data', file_name )\n",
    "    dados = mne.read_epochs_eeglab(path_)\n",
    "    channel_names = dados.info['ch_names']\n",
    "    subject_id = file_name[:3]\n",
    "    \n",
    "    # Extract labels\n",
    "    proCorr_antiCorr_labels = len(dados['proCorr','antiCorr'].get_data())\n",
    "    proErr_antiErr_nogoErr_labels = len(dados['proErr','antiErr','nogoErr'].get_data())\n",
    "    labels1[subject_id] = np.array([0] * proCorr_antiCorr_labels + [1] * proErr_antiErr_nogoErr_labels)\n",
    "    \n",
    "    # Initialize channel data dictionary\n",
    "    channel_data = {}\n",
    "    \n",
    "    # Iterate over 'proCorr' and 'antiCorr' events\n",
    "    for epoch_values in dados['proCorr','antiCorr'].get_data():\n",
    "        for channel_index, channel_values in enumerate(epoch_values):\n",
    "            channel_name = channel_names[channel_index]\n",
    "            if channel_name not in channel_data:\n",
    "                channel_data[channel_name] = []\n",
    "            channel_data[channel_name].append(list(channel_values))\n",
    "    \n",
    "    # Iterate over 'proErr', 'antiErr', and 'nogoErr' events\n",
    "    for epoch_values in dados['proErr','antiErr','nogoErr'].get_data():\n",
    "        for channel_index, channel_values in enumerate(epoch_values):\n",
    "            channel_name = channel_names[channel_index]\n",
    "            if channel_name not in channel_data:\n",
    "                channel_data[channel_name] = []\n",
    "            channel_data[channel_name].append(list(channel_values))\n",
    "    \n",
    "    data1[subject_id] = channel_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2={}\n",
    "labels2={}\n",
    "path='Dataset2'\n",
    "for files in os.listdir(path):\n",
    "    folders=os.path.join(path,files)\n",
    "    file2=[item for item in os.listdir(folders) if item.endswith('set')]\n",
    "#--------------------------------------------------------------------------\n",
    "    i=0\n",
    "    label=[]\n",
    "    while i!=4:\n",
    "        for file_index, file_name in enumerate(file2):\n",
    "            i=i+1\n",
    "            path_ = os.path.join( folders, file_name )\n",
    "            dados = mne.read_epochs_eeglab(path_)\n",
    "            channel_names = dados.info['ch_names']\n",
    "            subject_id = file_name[:3]\n",
    "            \n",
    "            # Extract labels\n",
    "            try:\n",
    "                Corr_labels = int(len(dados['150','160'].get_data()))\n",
    "            except:\n",
    "                Corr_labels=0\n",
    "            try:\n",
    "                Err_labels = int(len(dados['151','152','153','154','161','162','163','164'].get_data()))\n",
    "            except:\n",
    "                Err_labels=0\n",
    "            label.append(np.array([0] * Corr_labels + [1] * Err_labels))\n",
    "           \n",
    "    #--------------------------------------------------------------------------    \n",
    "            # Initialize channel data dictionary\n",
    "            channel_data = {}\n",
    "            data_channel=[]\n",
    "            try:\n",
    "                for epoch_values in dados['150','160'].get_data():\n",
    "                    for channel_index, channel_values in enumerate(epoch_values):\n",
    "                        channel_name = channel_names[channel_index]\n",
    "                        if channel_name not in channel_data:\n",
    "                            channel_data[channel_name] = []\n",
    "                        channel_data[channel_name].append(list(channel_values))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for epoch_values in dados['151','152','153','154','161','162','163','164'].get_data():\n",
    "                    for channel_index, channel_values in enumerate(epoch_values):\n",
    "                        channel_name = channel_names[channel_index]\n",
    "                        if channel_name not in channel_data:\n",
    "                            channel_data[channel_name] = []\n",
    "                        channel_data[channel_name].append(list(channel_values))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            data2[file_name] = channel_data\n",
    "        labels2[subject_id] = np.concatenate(label)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "rearranged_data = {}\n",
    "\n",
    "# Iterate through each file in data2\n",
    "for file_name, channel_data in data2.items():\n",
    "    # Extract the subject ID from the file name\n",
    "    subject_id = file_name.split('_')[0]\n",
    "    \n",
    "    # Initialize the subject in the rearranged_data dictionary if not already present\n",
    "    if subject_id not in rearranged_data:\n",
    "        rearranged_data[subject_id] = {}\n",
    "    \n",
    "    # Iterate through each channel in the current file\n",
    "    for channel, data in channel_data.items():\n",
    "        # Initialize the channel in the subject's dictionary if not already present\n",
    "        if channel not in rearranged_data[subject_id]:\n",
    "            rearranged_data[subject_id][channel] = []\n",
    "        \n",
    "        # Append the current file's data for the channel to the subject's channel data\n",
    "        rearranged_data[subject_id][channel].append(data)\n",
    "\n",
    "# Combine the data from different files of the same subject for each channel\n",
    "for subject_id, channels in rearranged_data.items():\n",
    "    for channel, data_list in channels.items():\n",
    "        # Flatten the list of data arrays into a single list or concatenate them\n",
    "        # Here we assume each data is a list or array; if not, adjust accordingly\n",
    "        combined_data = []\n",
    "        for data in data_list:\n",
    "            combined_data.extend(data)\n",
    "        rearranged_data[subject_id][channel] = combined_data\n",
    "\n",
    "# Now rearranged_data is in the desired format\n",
    "# You can print or further process the rearranged_data as needed\n",
    "\n",
    "data2=rearranged_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_post(data):\n",
    "    pre_response={}\n",
    "    post_response={}\n",
    "    for subject_id, dados in data.items():\n",
    "        channel_data_pre={}\n",
    "        channel_data_post={}\n",
    "        for channel_name, values in dados.items():\n",
    "            values_pre=[]\n",
    "            values_post=[]\n",
    "            for i in range(len(values)):\n",
    "                \n",
    "                index= int(len(values[i])/2)\n",
    "                values_pre.append(values[i][0:index])\n",
    "                values_post.append(values[i][index:-1])\n",
    "            channel_data_pre[channel_name]= values_pre\n",
    "            channel_data_post[channel_name]= values_post\n",
    "            \n",
    "        pre_response[subject_id] = channel_data_pre #(14,60,n_events,250)\n",
    "        post_response[subject_id] = channel_data_post\n",
    "    return pre_response, post_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_response1, post_response1 = data_pre_post(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_response2, post_response2 = data_pre_post(data2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
