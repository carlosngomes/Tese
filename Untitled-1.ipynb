{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P01\\P01_1.set...\n",
      "Not setting metadata\n",
      "75 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P01\\P01_2.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P01\\P01_3.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P01\\P01_4.set...\n",
      "Not setting metadata\n",
      "81 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P02\\P02_1.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P02\\P02_2.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P02\\P02_3.set...\n",
      "Not setting metadata\n",
      "77 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P02\\P02_4.set...\n",
      "Not setting metadata\n",
      "77 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P03\\P03_1.set...\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P03\\P03_2.set...\n",
      "Not setting metadata\n",
      "77 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P03\\P03_3.set...\n",
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P03\\P03_4.set...\n",
      "Not setting metadata\n",
      "77 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P04\\P04_1.set...\n",
      "Not setting metadata\n",
      "82 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P04\\P04_2.set...\n",
      "Not setting metadata\n",
      "70 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P04\\P04_3.set...\n",
      "Not setting metadata\n",
      "62 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P04\\P04_4.set...\n",
      "Not setting metadata\n",
      "68 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P05\\P05_1.set...\n",
      "Not setting metadata\n",
      "82 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P05\\P05_2.set...\n",
      "Not setting metadata\n",
      "70 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P05\\P05_3.set...\n",
      "Not setting metadata\n",
      "62 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P05\\P05_4.set...\n",
      "Not setting metadata\n",
      "68 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P06\\P06_1.set...\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P06\\P06_2.set...\n",
      "Not setting metadata\n",
      "63 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P06\\P06_3.set...\n",
      "Not setting metadata\n",
      "52 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P06\\P06_4.set...\n",
      "Not setting metadata\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P08\\P08_1.set...\n",
      "Not setting metadata\n",
      "76 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P08\\P08_2.set...\n",
      "Not setting metadata\n",
      "76 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P08\\P08_3.set...\n",
      "Not setting metadata\n",
      "75 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P08\\P08_4.set...\n",
      "Not setting metadata\n",
      "78 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P09\\P09_1.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P09\\P09_2.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P09\\P09_3.set...\n",
      "Not setting metadata\n",
      "81 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P09\\P09_4.set...\n",
      "Not setting metadata\n",
      "78 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P11\\P11_1.set...\n",
      "Not setting metadata\n",
      "66 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P11\\P11_2.set...\n",
      "Not setting metadata\n",
      "43 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P11\\P11_3.set...\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P11\\P11_4.set...\n",
      "Not setting metadata\n",
      "56 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P12\\P12_1.set...\n",
      "Not setting metadata\n",
      "77 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P12\\P12_2.set...\n",
      "Not setting metadata\n",
      "81 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P12\\P12_3.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P12\\P12_4.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P13\\P13_1.set...\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P13\\P13_2.set...\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P13\\P13_3.set...\n",
      "Not setting metadata\n",
      "69 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P13\\P13_4.set...\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P14\\P14_1.set...\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P14\\P14_2.set...\n",
      "Not setting metadata\n",
      "76 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P14\\P14_3.set...\n",
      "Not setting metadata\n",
      "75 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P14\\P14_4.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P15\\P15_1.set...\n",
      "Not setting metadata\n",
      "82 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P15\\P15_2.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P15\\P15_3.set...\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P15\\P15_4.set...\n",
      "Not setting metadata\n",
      "81 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P16\\P16_1.set...\n",
      "Not setting metadata\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P16\\P16_2.set...\n",
      "Not setting metadata\n",
      "67 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P16\\P16_3.set...\n",
      "Not setting metadata\n",
      "59 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P16\\P16_4.set...\n",
      "Not setting metadata\n",
      "59 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P17\\P17_1.set...\n",
      "Not setting metadata\n",
      "68 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P17\\P17_2.set...\n",
      "Not setting metadata\n",
      "71 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P17\\P17_3.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P17\\P17_4.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P18\\P18_1.set...\n",
      "Not setting metadata\n",
      "56 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P18\\P18_2.set...\n",
      "Not setting metadata\n",
      "54 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P18\\P18_3.set...\n",
      "Not setting metadata\n",
      "59 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P18\\P18_4.set...\n",
      "Not setting metadata\n",
      "69 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P19\\P19_1.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P19\\P19_2.set...\n",
      "Not setting metadata\n",
      "77 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P19\\P19_3.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P19\\P19_4.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P20\\P20_1.set...\n",
      "Not setting metadata\n",
      "75 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P20\\P20_2.set...\n",
      "Not setting metadata\n",
      "75 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P20\\P20_3.set...\n",
      "Not setting metadata\n",
      "75 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P20\\P20_4.set...\n",
      "Not setting metadata\n",
      "78 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P21\\P21_1.set...\n",
      "Not setting metadata\n",
      "47 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P21\\P21_2.set...\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P21\\P21_3.set...\n",
      "Not setting metadata\n",
      "37 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P21\\P21_4.set...\n",
      "Not setting metadata\n",
      "41 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P22\\P22_1.set...\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P22\\P22_2.set...\n",
      "Not setting metadata\n",
      "78 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P22\\P22_3.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\User\\Documents\\GitHub\\Tese\\Dataset2\\P22\\P22_4.set...\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import src.functions as src\n",
    "\n",
    "fs=500\n",
    "freq_bands={'delta' : [0,4],\n",
    "            'theta' : [4,8],\n",
    "            'alpha' : [8, 13],\n",
    "            'beta' : [13,35],\n",
    "            'high' : [35, 45],\n",
    "            'all': [1.5,45],\n",
    "            'low': [1.5,12]}\n",
    "\n",
    "data2={}\n",
    "labels2={}\n",
    "path='Dataset2'\n",
    "for files in os.listdir(path):\n",
    "    folders=os.path.join(path,files)\n",
    "    file2=[item for item in os.listdir(folders) if item.endswith('set')]\n",
    "#--------------------------------------------------------------------------\n",
    "    i=0\n",
    "    label=[]\n",
    "    while i!=4:\n",
    "        for file_index, file_name in enumerate(file2):\n",
    "            i=i+1\n",
    "            path_ = os.path.join( folders, file_name )\n",
    "            dados = mne.read_epochs_eeglab(path_)\n",
    "            channel_names2 = dados.info['ch_names']\n",
    "            subject_id = file_name[:3]\n",
    "            \n",
    "            # Extract labels\n",
    "            try:\n",
    "                Corr_labels = int(len(dados['150','160'].get_data()))\n",
    "            except:\n",
    "                Corr_labels=0\n",
    "            try:\n",
    "                Err_labels = int(len(dados['151','152','153','154','161','162','163','164'].get_data()))\n",
    "            except:\n",
    "                Err_labels=0\n",
    "            label.append(np.array([0] * Corr_labels + [1] * Err_labels))\n",
    "           \n",
    "    #--------------------------------------------------------------------------    \n",
    "            # Initialize channel data dictionary\n",
    "            channel_data = {}\n",
    "            data_channel=[]\n",
    "            try:\n",
    "                for epoch_values in dados['150','160'].get_data():\n",
    "                    for channel_index, channel_values in enumerate(epoch_values):\n",
    "                        channel_name = channel_names2[channel_index]\n",
    "                        if channel_name not in channel_data:\n",
    "                            channel_data[channel_name] = []\n",
    "                        channel_data[channel_name].append(list(channel_values))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for epoch_values in dados['151','152','153','154','161','162','163','164'].get_data():\n",
    "                    for channel_index, channel_values in enumerate(epoch_values):\n",
    "                        channel_name = channel_names2[channel_index]\n",
    "                        if channel_name not in channel_data:\n",
    "                            channel_data[channel_name] = []\n",
    "                        channel_data[channel_name].append(list(channel_values))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            data2[file_name] = channel_data\n",
    "        labels2[subject_id] = np.concatenate(label)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "rearranged_data = {}\n",
    "\n",
    "# Iterate through each file in data2\n",
    "for file_name, channel_data in data2.items():\n",
    "    # Extract the subject ID from the file name\n",
    "    subject_id = file_name.split('_')[0]\n",
    "    \n",
    "    # Initialize the subject in the rearranged_data dictionary if not already present\n",
    "    if subject_id not in rearranged_data:\n",
    "        rearranged_data[subject_id] = {}\n",
    "    \n",
    "    # Iterate through each channel in the current file\n",
    "    for channel, data in channel_data.items():\n",
    "        # Initialize the channel in the subject's dictionary if not already present\n",
    "        if channel not in rearranged_data[subject_id]:\n",
    "            rearranged_data[subject_id][channel] = []\n",
    "        \n",
    "        # Append the current file's data for the channel to the subject's channel data\n",
    "        rearranged_data[subject_id][channel].append(data)\n",
    "\n",
    "# Combine the data from different files of the same subject for each channel\n",
    "for subject_id, channels in rearranged_data.items():\n",
    "    for channel, data_list in channels.items():\n",
    "        # Flatten the list of data arrays into a single list or concatenate them\n",
    "        # Here we assume each data is a list or array; if not, adjust accordingly\n",
    "        combined_data = []\n",
    "        for data in data_list:\n",
    "            combined_data.extend(data)\n",
    "        rearranged_data[subject_id][channel] = combined_data\n",
    "\n",
    "# Now rearranged_data is in the desired format\n",
    "# You can print or further process the rearranged_data as needed\n",
    "\n",
    "data2=rearranged_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_post(data):\n",
    "    pre_response={}\n",
    "    post_response={}\n",
    "    for subject_id, dados in data.items():\n",
    "        channel_data_pre={}\n",
    "        channel_data_post={}\n",
    "        for channel_name, values in dados.items():\n",
    "            values_pre=[]\n",
    "            values_post=[]\n",
    "            for i in range(len(values)):\n",
    "                \n",
    "                index= int(len(values[i])/2)\n",
    "                values_pre.append(values[i][0:index])\n",
    "                values_post.append(values[i][index:-1])\n",
    "            channel_data_pre[channel_name]= values_pre\n",
    "            channel_data_post[channel_name]= values_post\n",
    "            \n",
    "        pre_response[subject_id] = channel_data_pre #(14,60,n_events,250)\n",
    "        post_response[subject_id] = channel_data_post\n",
    "    return pre_response, post_response\n",
    "\n",
    "pre_response2, post_response2 = data_pre_post(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pre2,S_pre2= src.getpsd(pre_response2,fs)    # S_pre ->(14,60,n_events,n_points)\n",
    "f_post2,S_post2= src.getpsd(post_response2,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_per_channel2= src.getdataperchannel(S_pre2) #(subject_id,60,n_events,n_points)\n",
    "post_data_per_channel2= src.getdataperchannel(S_post2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1= src.feature('fcz_features','.','.','theta','all',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2, f_post2)\n",
    "feature2= src.feature('fcz_features','.','.','theta','high',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2)\n",
    "feature3= src.feature('fcz_features','.','.','theta','all',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2)\n",
    "feature4= src.feature('fcz_features','.','.','theta','high',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2)\n",
    "feature5= src.feature('fcz_features','.','.','theta','other',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2)\n",
    "feature6= src.feature('fcz_features','.','.','theta','other',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2)\n",
    "feature7= src.feature('fcz_features','.','.','theta','theta',post_data_per_channel2,pre_data_per_channel2,freq_bands,f_post2,f_pre2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= feature1\n",
    "data2= feature2\n",
    "data3= feature3\n",
    "data4= feature4\n",
    "data5= feature5\n",
    "data6= feature6\n",
    "data7= feature7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data8={}\n",
    "data9={}\n",
    "data10={}\n",
    "data11={}\n",
    "data12={}\n",
    "data13={}\n",
    "data14={}\n",
    "data15={}\n",
    "data16={}\n",
    "for channel_name in post_data_per_channel2['P01'].keys():    \n",
    "    feature8= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','all',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature9= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','high',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature10= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','all',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature11= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','high',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature12= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','theta',post_data_per_channel2,pre_data_per_channel2,freq_bands,f_post2,f_pre2))\n",
    "    feature13= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','delta',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature14= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','alpha',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature15= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','delta',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature16= src.extend_list(src.feature('all_features',channel_name,channel_name,'theta','alpha',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    data8[channel_name]=feature8\n",
    "    data9[channel_name]=feature9\n",
    "    data10[channel_name]=feature10\n",
    "    data11[channel_name]=feature11\n",
    "    data12[channel_name]=feature12\n",
    "    data13[channel_name]=feature13\n",
    "    data14[channel_name]=feature14\n",
    "    data15[channel_name]=feature15\n",
    "    data16[channel_name]=feature16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data17={}\n",
    "data18={}\n",
    "for channel_name in post_data_per_channel2['P01'].keys():\n",
    "    feature17= src.extend_list(src.feature('midfrontal_features',channel_name,channel_name,'theta','other',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature18= src.extend_list(src.feature('midfrontal_features',channel_name,channel_name,'theta','other',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    data17[channel_name]=feature17\n",
    "    data18[channel_name]=feature18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data19={}\n",
    "data20={}\n",
    "data21={}\n",
    "data22={}\n",
    "data23={}\n",
    "data24={}\n",
    "data25={}\n",
    "data26={}\n",
    "data27={}\n",
    "data28={}\n",
    "data29={}\n",
    "data30={}\n",
    "for channel_name in post_data_per_channel2[subject_id].keys():        \n",
    "    \n",
    "    feature19= src.extend_list(src.feature('low_features',channel_name,channel_name,'delta','all',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature20= src.extend_list(src.feature('low_features',channel_name,channel_name,'alpha','all',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature21= src.extend_list(src.feature('low_features',channel_name,channel_name,'low','all',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature22= src.extend_list(src.feature('low_features',channel_name,channel_name,'delta','high',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature23= src.extend_list(src.feature('low_features',channel_name,channel_name,'alpha','high',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature24= src.extend_list(src.feature('low_features',channel_name,channel_name,'low','high',post_data_per_channel2,post_data_per_channel2,freq_bands,f_post2,f_post2))\n",
    "    feature25= src.extend_list(src.feature('low_features',channel_name,channel_name,'delta','all',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature26= src.extend_list(src.feature('low_features',channel_name,channel_name,'alpha','all',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature27= src.extend_list(src.feature('low_features',channel_name,channel_name,'low','all',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature28= src.extend_list(src.feature('low_features',channel_name,channel_name,'delta','high',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature29= src.extend_list(src.feature('low_features',channel_name,channel_name,'alpha','high',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    feature30= src.extend_list(src.feature('low_features',channel_name,channel_name,'low','high',pre_data_per_channel2,pre_data_per_channel2,freq_bands,f_pre2,f_pre2))\n",
    "    data19[channel_name]=feature19\n",
    "    data20[channel_name]=feature20\n",
    "    data21[channel_name]=feature21\n",
    "    data22[channel_name]=feature22\n",
    "    data23[channel_name]=feature23\n",
    "    data24[channel_name]=feature24\n",
    "    data25[channel_name]=feature25\n",
    "    data26[channel_name]=feature26\n",
    "    data27[channel_name]=feature27\n",
    "    data28[channel_name]=feature28\n",
    "    data29[channel_name]=feature29\n",
    "    data30[channel_name]=feature30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature31={}\n",
    "feature32={}\n",
    "FCZ_Cluster=['FZ','FC1','FCZ','FC2','CZ']\n",
    "PE_Cluster=['CPZ','P1','PZ','P2','POZ']\n",
    "for subject_id,values in post_response2.items():\n",
    "    mean_all70_160_values = []\n",
    "    mean_all200_500_values = []\n",
    "    for i in range(len(next(iter(values.values())))):\n",
    "        all70_160_values = []\n",
    "        all200_500_values = []\n",
    "        for channel_name, channel_values in values.items():   \n",
    "            if channel_name in FCZ_Cluster:         \n",
    "                all70_160_values.append(np.mean(channel_values[i][35:81]))\n",
    "            elif channel_name in PE_Cluster:\n",
    "                all200_500_values.append(np.mean(channel_values[i][100:-1]))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        mean_all70_160_values.append(np.mean(all70_160_values))\n",
    "        mean_all200_500_values.append(np.mean(all200_500_values))\n",
    "    feature31[subject_id]= mean_all70_160_values\n",
    "    feature32[subject_id]= mean_all200_500_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data31=src.extend_list(feature31)\n",
    "data32=src.extend_list(feature32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               FP1           FPZ           FP2           AF3           AF4  \\\n",
      "0     1.413131e-07 -3.103566e-07 -5.394740e-09  2.442112e-07 -4.652011e-07   \n",
      "1     5.025053e-07  3.288155e-07  1.602803e-07  8.346278e-07 -1.593555e-07   \n",
      "2     1.516324e-06  1.580863e-06  1.559507e-06  1.729047e-06  1.514190e-06   \n",
      "3    -1.189370e-06 -1.130375e-06 -1.299153e-06 -7.301966e-07 -1.078808e-06   \n",
      "4     1.512657e-06  1.246212e-06  1.087998e-06  1.267356e-06  1.071369e-06   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "5718  1.266326e-06  3.824442e-06  1.499868e-10 -4.625618e-07  6.675504e-07   \n",
      "5719 -1.494198e-06 -3.700178e-06 -6.702091e-07 -2.566784e-06 -1.075214e-06   \n",
      "5720 -2.062495e-06 -5.272965e-06 -3.004995e-06  1.101469e-07 -2.155927e-06   \n",
      "5721  2.603466e-06  1.994088e-06  3.908386e-06  5.899276e-06  3.358396e-06   \n",
      "5722  3.277121e-06  4.932089e-06 -8.771706e-07  3.805540e-06  3.806297e-08   \n",
      "\n",
      "                F7            F5            F3            F1            FZ  \\\n",
      "0     1.781529e-07  2.306443e-07  2.272783e-07  7.369242e-08  1.873502e-07   \n",
      "1     1.349424e-07  1.567355e-07  2.359431e-07  4.101675e-07  4.914180e-07   \n",
      "2     1.037737e-07  1.005351e-07  1.838653e-07  4.090070e-07  3.361563e-07   \n",
      "3     7.041103e-08  1.378321e-07  2.022044e-07  1.319200e-07  1.373815e-07   \n",
      "4     4.380226e-07  5.509892e-07  6.080703e-07  6.559835e-07  3.938959e-07   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "5718 -1.736601e-06  2.848672e-06 -1.746417e-06 -2.340883e-06 -1.990319e-06   \n",
      "5719  3.084529e-06  3.203872e-06 -8.763310e-07 -2.089408e-06 -3.275208e-06   \n",
      "5720 -5.678996e-06 -8.026416e-06 -1.122963e-06  1.090927e-07 -1.026194e-06   \n",
      "5721  5.208944e-06  1.059408e-06  4.148609e-06  2.843272e-06  1.476613e-06   \n",
      "5722 -3.386887e-06  1.297159e-06 -1.159374e-06  4.607315e-07  9.150236e-07   \n",
      "\n",
      "      ...           PO7           PO5           PO3           POZ  \\\n",
      "0     ... -1.838405e-08 -1.511578e-07  1.648985e-09  2.326227e-07   \n",
      "1     ...  1.281794e-07  1.877095e-07  1.169601e-07  1.158912e-07   \n",
      "2     ...  1.936076e-07  3.486624e-07  1.751491e-07  6.839949e-08   \n",
      "3     ... -4.770780e-07 -2.928120e-07 -1.026809e-08  7.009722e-08   \n",
      "4     ... -2.711159e-08 -1.710189e-07 -5.186263e-07 -3.257514e-07   \n",
      "...   ...           ...           ...           ...           ...   \n",
      "5718  ...  9.817353e-07  3.796714e-06  1.699590e-06  1.077354e-06   \n",
      "5719  ... -3.184034e-06  2.733299e-06  3.987627e-06  3.611928e-06   \n",
      "5720  ...  2.788847e-06  8.981451e-07  2.445902e-06  2.624521e-06   \n",
      "5721  ...  9.456554e-07 -3.729604e-06 -3.786592e-06 -3.746010e-06   \n",
      "5722  ...  2.573252e-06 -1.645494e-06 -1.237455e-06 -6.701148e-07   \n",
      "\n",
      "               PO4           PO6           PO8            O1            OZ  \\\n",
      "0     1.791185e-07  1.346547e-08 -1.664186e-07  9.355878e-08  1.275616e-07   \n",
      "1     5.965115e-07  1.256048e-06  8.278164e-07  1.884826e-07  3.014130e-07   \n",
      "2     6.203049e-07  5.823458e-07  4.503530e-07  6.088723e-07  6.034275e-07   \n",
      "3    -3.874991e-07 -9.850172e-07 -6.277572e-07 -7.094498e-07 -5.996995e-07   \n",
      "4     3.331473e-07  5.813513e-07  1.901645e-07  2.655687e-07  4.806842e-07   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "5718 -2.776804e-06 -1.102358e-06 -9.386016e-07  2.222213e-06  2.667670e-06   \n",
      "5719  3.083794e-06  3.662366e-06  9.093004e-07  5.625136e-07 -1.578161e-07   \n",
      "5720  4.857564e-06  3.015736e-06 -1.988777e-06 -5.576159e-07  3.183203e-06   \n",
      "5721 -4.260763e-06 -4.457634e-06 -4.588076e-06 -3.739055e-06 -3.216018e-06   \n",
      "5722 -8.413545e-07 -2.961209e-06 -2.705043e-06 -6.421729e-07 -2.308007e-06   \n",
      "\n",
      "                O2  \n",
      "0     1.420752e-08  \n",
      "1     2.221678e-07  \n",
      "2     6.355745e-07  \n",
      "3    -9.135224e-07  \n",
      "4     6.078733e-07  \n",
      "...            ...  \n",
      "5718  3.267565e-06  \n",
      "5719 -3.715465e-07  \n",
      "5720  9.500313e-08  \n",
      "5721 -2.408971e-06  \n",
      "5722 -7.875497e-07  \n",
      "\n",
      "[5723 rows x 60 columns]\n",
      "               FP1           FPZ           FP2           AF3           AF4  \\\n",
      "0     2.888564e-07  9.372662e-07  2.307201e-07  9.418236e-08  7.205140e-07   \n",
      "1    -1.113075e-07  5.147266e-07  8.184439e-07  2.333324e-07  1.118402e-06   \n",
      "2    -1.987612e-07 -2.499480e-07 -1.650433e-07  7.821571e-08 -2.849123e-07   \n",
      "3     1.500826e-06  1.534364e-06  1.731935e-06  1.068163e-06  1.541015e-06   \n",
      "4    -1.319471e-06 -8.577962e-07 -5.565604e-07 -1.038504e-06 -7.372111e-07   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "5718  2.111699e-07  5.733952e-07  1.458059e-06 -2.417796e-07  1.121558e-06   \n",
      "5719 -1.551281e-06 -1.618901e-06 -1.077456e-06 -1.395318e-06 -9.532679e-07   \n",
      "5720  6.981254e-07  1.337338e-06  2.409413e-06  1.774148e-06  4.429859e-07   \n",
      "5721  4.473234e-07  1.357549e-06  6.479782e-07 -6.754547e-07  7.533953e-07   \n",
      "5722  1.178517e-06  5.940337e-07 -9.878927e-07  2.430994e-06 -1.274158e-07   \n",
      "\n",
      "                F7            F5            F3            F1            FZ  \\\n",
      "0     6.005020e-08  7.786421e-08  2.219669e-07  6.910123e-07  5.759450e-07   \n",
      "1     2.294065e-07  3.134832e-07  3.644999e-07  3.546587e-07  1.003511e-06   \n",
      "2     5.397428e-07  6.922877e-07  8.135602e-07  9.604374e-07  1.358613e-06   \n",
      "3     7.201194e-08  7.828899e-08  1.191007e-08 -4.969478e-08 -4.540555e-07   \n",
      "4    -2.616015e-07 -3.608859e-07 -4.288718e-07 -5.238176e-07 -1.296685e-07   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "5718  1.899067e-06  9.224462e-07  2.144003e-06 -3.490783e-07 -6.644718e-07   \n",
      "5719 -3.876547e-06 -3.307952e-06 -1.303242e-06 -1.046877e-06 -1.391061e-06   \n",
      "5720  1.000847e-06  1.457447e-06  2.618280e-07 -7.123877e-07 -7.070209e-07   \n",
      "5721  1.846962e-07  1.922670e-06 -9.120379e-07 -1.581709e-06 -7.007133e-07   \n",
      "5722 -1.575612e-06 -3.575103e-06  6.521326e-08  1.941129e-08 -9.501326e-07   \n",
      "\n",
      "      ...           PO7           PO5           PO3           POZ  \\\n",
      "0     ... -2.818158e-08  2.369618e-07 -1.027433e-07 -6.063197e-07   \n",
      "1     ... -7.207598e-07 -5.575932e-07 -7.533032e-07 -7.786332e-07   \n",
      "2     ... -1.742729e-07 -5.610020e-07 -4.832649e-07 -1.146023e-06   \n",
      "3     ...  2.981123e-07  1.414119e-08 -2.204526e-07 -1.771111e-07   \n",
      "4     ... -3.232548e-07 -1.269400e-07  5.084923e-08 -2.103957e-07   \n",
      "...   ...           ...           ...           ...           ...   \n",
      "5718  ... -2.377493e-06  5.213162e-07 -1.477026e-07 -2.030072e-06   \n",
      "5719  ... -1.215565e-08  1.869030e-06  1.917783e-06  9.464441e-07   \n",
      "5720  ...  2.159569e-07 -1.105126e-06 -1.502352e-06 -2.788589e-06   \n",
      "5721  ... -1.319349e-07 -2.364560e-06 -1.618695e-06 -6.762355e-07   \n",
      "5722  ...  2.207933e-07  8.826745e-07  4.561602e-07 -6.925095e-07   \n",
      "\n",
      "               PO4           PO6           PO8            O1            OZ  \\\n",
      "0    -6.050445e-07  7.339633e-08  1.748227e-07  5.592455e-08 -4.515350e-08   \n",
      "1    -1.070413e-06 -1.556821e-06 -1.229294e-06 -9.434732e-07 -9.341392e-07   \n",
      "2    -1.941242e-06 -1.797821e-06 -1.647534e-06 -1.166787e-06 -1.537436e-06   \n",
      "3     3.430004e-07  1.386874e-06  8.475851e-07  5.263208e-07  7.844172e-07   \n",
      "4    -1.064267e-06 -1.185672e-06 -7.421618e-07 -4.543301e-07 -6.807124e-07   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "5718 -5.262483e-07  1.103047e-07 -1.028398e-06 -1.001680e-06 -1.900045e-06   \n",
      "5719  1.864966e-06  6.979608e-07  3.022322e-06  4.904247e-07 -2.086299e-06   \n",
      "5720 -1.886240e-06  4.805375e-07 -6.779091e-07 -2.233692e-06  1.646072e-07   \n",
      "5721 -8.158239e-07  9.255653e-07 -1.413355e-06 -5.611868e-07  5.919580e-07   \n",
      "5722  4.571692e-07 -8.777426e-07  6.701802e-07  8.450344e-07  5.409890e-07   \n",
      "\n",
      "                O2  \n",
      "0    -1.601216e-08  \n",
      "1    -1.274949e-06  \n",
      "2    -1.673506e-06  \n",
      "3     7.891543e-07  \n",
      "4    -9.314997e-07  \n",
      "...            ...  \n",
      "5718 -2.321736e-08  \n",
      "5719  2.399446e-07  \n",
      "5720  3.021176e-07  \n",
      "5721 -1.206027e-06  \n",
      "5722  3.873155e-07  \n",
      "\n",
      "[5723 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize the dictionaries to store the results\n",
    "feature33 = {}\n",
    "feature34 = {}\n",
    "\n",
    "# Iterate over each subject in the pre_response2 dictionary\n",
    "for subject_id, values in pre_response2.items():\n",
    "    # Iterate over each channel in the subject's data\n",
    "    for channel_name, channel_values in values.items():\n",
    "        # If the channel is not yet in the feature dictionaries, initialize it\n",
    "        if channel_name not in feature33:\n",
    "            feature33[channel_name] = []\n",
    "        if channel_name not in feature34:\n",
    "            feature34[channel_name] = []\n",
    "        \n",
    "        # Iterate over each event in the channel values\n",
    "        for i in range(len(channel_values)):\n",
    "            # Calculate the mean values for the specified ranges\n",
    "            mean_500_250 = np.mean(channel_values[i][0:126])\n",
    "            mean_250_0 = np.mean(channel_values[i][125:-1])\n",
    "            \n",
    "            # Append the mean values to the corresponding channel's list in the feature dictionaries\n",
    "            feature33[channel_name].append(mean_500_250)\n",
    "            feature34[channel_name].append(mean_250_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data33=feature33\n",
    "data34=feature34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the dictionaries to store the results\n",
    "feature35 = {}\n",
    "feature36 = {}\n",
    "\n",
    "# Iterate over each subject in the pre_response2 dictionary\n",
    "for subject_id, values in post_response2.items():\n",
    "    # Iterate over each channel in the subject's data\n",
    "    for channel_name, channel_values in values.items():\n",
    "        # If the channel is not yet in the feature dictionaries, initialize it\n",
    "        if channel_name not in feature35:\n",
    "            feature35[channel_name] = []\n",
    "        if channel_name not in feature36:\n",
    "            feature36[channel_name] = []\n",
    "        \n",
    "        # Iterate over each event in the channel values\n",
    "        for i in range(len(channel_values)):\n",
    "            # Calculate the mean values for the specified ranges\n",
    "            mean_0_250 = np.mean(channel_values[i][0:126])\n",
    "            mean_250_500 = np.mean(channel_values[i][125:-1])\n",
    "            \n",
    "            # Append the mean values to the corresponding channel's list in the feature dictionaries\n",
    "            feature35[channel_name].append(mean_0_250)\n",
    "            feature36[channel_name].append(mean_250_500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data35=feature35\n",
    "data36=feature36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1_0        2_0       3_0         4_0       5_0       6_0       7_0  \\\n",
      "0     3.592698  26.829925  5.745963   63.546782  2.266614  1.845827  0.480871   \n",
      "1     3.482047  39.558126  4.761085   75.572530  1.427781  1.744615  0.506495   \n",
      "2     5.349382  71.950483  3.881196   71.459373  1.393783  1.327750  1.020635   \n",
      "3     4.858630  82.359310  5.047433  130.558392  3.048974  1.733904  1.441585   \n",
      "4     6.138034  58.718459  5.398434  191.862086  1.692413  1.940198  0.754368   \n",
      "...        ...        ...       ...         ...       ...       ...       ...   \n",
      "5718  2.332497  19.782686  2.898027   19.550448  0.826799  1.055001  0.811509   \n",
      "5719  4.054956  15.898670  4.077211   57.923930  1.728021  1.074733  0.760379   \n",
      "5720  2.237373   9.829327  3.094753   19.413191  0.971102  0.733325  0.944181   \n",
      "5721  6.677481  75.616428  3.200734   50.046812  2.476001  1.503801  2.451988   \n",
      "5722  5.287280  94.066738  2.842601   32.006040  1.939726  1.390125  3.464484   \n",
      "\n",
      "         8_FP1     8_FPZ     8_FP2  ...        36_PO7        36_PO5  \\\n",
      "0     0.493801  0.363747  0.873742  ... -4.258930e-07 -5.450195e-07   \n",
      "1     3.276006  5.101954  3.420121  ...  2.404754e-07  2.975304e-08   \n",
      "2     7.269073  6.403942  7.457445  ...  9.060281e-07  6.240260e-07   \n",
      "3     0.537128  0.933747  2.808357  ...  6.731771e-07  6.669647e-07   \n",
      "4     1.437747  2.091436  2.836995  ...  9.393873e-07  7.292361e-07   \n",
      "...        ...       ...       ...  ...           ...           ...   \n",
      "5718  1.270310  0.755486  2.130908  ...  5.035534e-08 -4.833107e-06   \n",
      "5719  1.982567  1.815171  0.653605  ...  1.756973e-07 -2.097971e-06   \n",
      "5720  1.719787  2.067610  0.203549  ...  2.086128e-07  1.258474e-06   \n",
      "5721  1.742598  1.587936  6.086343  ... -1.436356e-06  2.682272e-06   \n",
      "5722  4.830840  2.161953  4.502160  ... -2.450851e-06 -1.678206e-06   \n",
      "\n",
      "            36_PO3        36_POZ        36_PO4        36_PO6        36_PO8  \\\n",
      "0    -1.802797e-07  1.969757e-07  3.044400e-07 -5.098261e-07 -2.947315e-07   \n",
      "1    -1.601282e-07 -4.529808e-07 -4.820773e-07 -5.583303e-07 -5.073189e-07   \n",
      "2     4.597944e-07 -3.532591e-07 -7.519246e-07 -4.470046e-07 -2.231720e-07   \n",
      "3     7.995201e-07  4.374990e-07  3.404965e-07 -6.255954e-09 -1.018519e-07   \n",
      "4     7.392132e-07  5.876396e-07  6.566388e-07 -1.949045e-07  3.248983e-07   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "5718 -3.879683e-06 -1.030977e-06  6.017988e-07 -1.421503e-06 -6.189065e-08   \n",
      "5719 -3.285307e-06 -1.959997e-06 -2.477728e-06 -2.326327e-06 -1.993031e-06   \n",
      "5720  1.933774e-06  3.557204e-06  5.909483e-07 -1.082697e-06  2.852045e-06   \n",
      "5721  1.157689e-07 -8.375135e-07  6.797279e-07  1.360861e-06  3.684341e-06   \n",
      "5722 -6.313781e-07 -1.346713e-06 -2.194834e-06  1.131829e-06  6.527747e-07   \n",
      "\n",
      "             36_O1         36_OZ         36_O2  \n",
      "0    -5.169848e-07 -4.782453e-07 -1.973423e-07  \n",
      "1    -1.422089e-07 -6.559100e-08 -4.409020e-07  \n",
      "2     4.766947e-07  4.240741e-07  1.491280e-07  \n",
      "3     5.498992e-07  1.531621e-07  2.437212e-07  \n",
      "4     9.970336e-07  1.060300e-06  1.171003e-06  \n",
      "...            ...           ...           ...  \n",
      "5718 -3.401387e-06 -2.757035e-06 -4.617630e-06  \n",
      "5719 -1.185298e-06  1.944505e-08 -4.111453e-07  \n",
      "5720  5.229748e-06 -1.286991e-06  1.713117e-06  \n",
      "5721  1.222053e-06 -2.184109e-06  1.154928e-06  \n",
      "5722 -3.081466e-06  7.430875e-07 -2.344567e-06  \n",
      "\n",
      "[5723 rows x 1629 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dicts=[]\n",
    "for feature_index in range(1,37):\n",
    "    feature_corr_key = 'data{}'.format(feature_index)\n",
    "    dicts.append(globals()[feature_corr_key])\n",
    "\n",
    "\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "# Iterate through each dictionary and its index\n",
    "for index, feature_dict in enumerate(dicts, start=1):\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame(feature_dict)\n",
    "    # Rename the columns to include the iteration number\n",
    "    df.columns = [f'{index}_{col}' for col in df.columns]\n",
    "    # Concatenate the DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], axis=1)\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('dataset2_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
